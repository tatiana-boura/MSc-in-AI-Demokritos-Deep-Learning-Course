{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ab4add",
   "metadata": {},
   "source": [
    "# Predicting Satisfiability of SAT-3 Problems\n",
    "## Solving the Classification Task using a ***Long Short-Term Memory (LSTM)*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1811576",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836b5e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "__counter__ = random.randint(0,2e9)\n",
    "\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f6b006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import json\n",
    "\n",
    "from tuning import tune_parameters\n",
    "from data_loader import dataset_processing\n",
    "from train import training, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d6109",
   "metadata": {},
   "source": [
    "### Training and Evaluation process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d59a9e",
   "metadata": {},
   "source": [
    "In order to train the model, a *training set* is used alongside with a *validation set*. The latter is used to measure the performance of the model. The training and validation set were extracted from the 80% (60%-20%) of the data and the rest 20% was kept to evaluate the model after its training (*test set*).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a977c44e",
   "metadata": {},
   "source": [
    "**Create the dataset**: The dataset is created from the raw data in such a format that it can be loader by the *DataLoader* module of torch.utils.data. <br>\n",
    "\n",
    "In this case, the data was treated as *timeseries* with sequence length equal to 2. In order for that to be able to happen, some data augmentation was performed. Specifically, as noted by the dataset documentation (<a href=\"https://www.cs.ubc.ca/~hoos/SATLIB/Benchmarks/SAT/RND3SAT/descr.html\">Dataset Documentation</a>), for all problem instances there is a clause number-threshold after which the problem is highly unlikely to be satisfiable. So, before this threshold, the problem is most likely to be satisfiable and, for that reason, it is possible to augment the dataset in two ways :\n",
    "<ol>\n",
    "    <li>For each instance provide a satisfiable smaller version of it (the instance below the threshold).</li>\n",
    "    <li>For each unsatisfiable instance provide another unsatisfiable instance (the instance just above the threshold).</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f0454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the data processing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_weight = dataset_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d737409",
   "metadata": {},
   "source": [
    "It should be noted the LSTM model needs about 300 times more data that its parameters and in our case we have 970561 parameters and 14092 input data. **Thus, due to the amount of data, even after the augmentation, the model is not expected to reach high values in the evaluation metrics**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b7dd0",
   "metadata": {},
   "source": [
    "**Tune parameters**: Tune the parameters of the model (LSTM itself) as well as parameters regarding the training process e.g. *batch-size*, *weight decay* etc. More specidically, the parameters that are tuned are the following.\n",
    "<ol><li>Model parameters:</li>\n",
    "    <ul> \n",
    "        <li>Number of layers</li>\n",
    "        <li>Dropout rate</li>\n",
    "        <li>Hidden Units</li><br>\n",
    "    </ul>\n",
    "    <li>Training parameters:</li>\n",
    "    <ul> \n",
    "        <li>Batch size used</li>\n",
    "        <li>Learning rate</li>\n",
    "        <li>Weight decay</li>\n",
    "    </ul>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e2055c",
   "metadata": {},
   "source": [
    "The parameters of the final model are the ones that result in the minimum ***validation error***. <br>\n",
    "Also, ***early stopping*** is used in order to avoid *overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc60b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune parameters\n",
    "best_parameters = tune_parameters(pos_weight=pos_weight)\n",
    "\n",
    "# Show best parameters\n",
    "print(f'Best hyperparameters were: {best_parameters}')\n",
    "# Store best parameters\n",
    "with open('./best_parameters_same_sets.txt', 'w') as f:\n",
    "    f.write(json.dumps(best_parameters))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff887d",
   "metadata": {},
   "source": [
    "**Train with the best parameters**: The LSTM is trained using the selected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the best parameters in order to train final model\n",
    "with open('best_parameters_same_sets.txt') as f:\n",
    "    data = f.read()\n",
    "\n",
    "best_parameters_loaded = json.loads(data)\n",
    "\n",
    "print('\\nNow training with the best parameters\\n')\n",
    "training(params=best_parameters_loaded, make_err_logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180905a7",
   "metadata": {},
   "source": [
    "The following Figure shows the ***training and validation set errors***, the epoch where the ***early stopping*** was activated, as well as the epoch of the final ***selected model***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef04a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML('<img src=\"plots/train_valid_error.png?%d\" height=400 width=400>' % __counter__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e64fc27",
   "metadata": {},
   "source": [
    "**Test the model**: Predict the satisfiability of the clauses in the *Test Set* and get the corresponding metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ae1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nResults on the test set:\\n')\n",
    "testing(params=best_parameters_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb56bf",
   "metadata": {},
   "source": [
    "The following **Figures** show:\n",
    "<ol>\n",
    "<li>The <b>confusion matrix</b> for the test set-prediction</li>\n",
    "<li>The <b>ROC-AUC curve</b> for the test set-prediction</li>\n",
    "<li>The <b>precision recall curve</b> for the test set-prediction</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d64565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"plots/cm.png?362456251\" height=500 width=500>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"plots/roc_auc.png?362456251\" height=450 width=450>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"plots/pr.png?362456251\" height=450 width=450>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n1.\")\n",
    "display(HTML('<img src=\"plots/cm.png?%d\" height=500 width=500>' % __counter__))\n",
    "print(\"2.\")\n",
    "display(HTML('<img src=\"plots/roc_auc.png?%d\" height=450 width=450>' % __counter__))\n",
    "print(\"3.\")\n",
    "display(HTML('<img src=\"plots/pr.png?%d\" height=450 width=450>' % __counter__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4ff524",
   "metadata": {},
   "source": [
    "Since, as one can notice, ***the results are not very promising using this model and this architecture***, with the current amount of data, the model is not tested on a Test Set from a different data distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepLearningNew)",
   "language": "python",
   "name": "deeplearningnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
